{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAX423 HW4\n",
    "## Jiaqi Lu, Qihan Guan, Edwin Liu, Kexin Wang, Liqi Yi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/jupyter/spark-3.1.1-bin-hadoop2.7') #code compiled in Google Cloud VM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import pyspark.sql.functions as function\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql.functions import concat\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType, FloatType\n",
    "import matplotlib.pyplot as plt\n",
    "import emoji #pip install emoji\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize spark session\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName('venmo')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------------+-------------------+------------+-----------+--------------------+\n",
      "|  user1|  user2|transaction_type|           datetime| description|is_business|            story_id|\n",
      "+-------+-------+----------------+-------------------+------------+-----------+--------------------+\n",
      "|1218774|1528945|         payment|2015-11-27 10:48:19|        Uber|      false|5657c473cd03c9af2...|\n",
      "|5109483|4782303|         payment|2015-06-17 11:37:04|      Costco|      false|5580f9702b64f70ab...|\n",
      "|4322148|3392963|         payment|2015-06-19 07:05:31|Sweaty balls|      false|55835ccb1a624b14a...|\n",
      "| 469894|1333620|          charge|2016-06-03 23:34:13|          üé•|      false|5751b185cd03c9af2...|\n",
      "|2960727|3442373|         payment|2016-05-29 23:23:42|           ‚ö°|      false|574b178ecd03c9af2...|\n",
      "+-------+-------+----------------+-------------------+------------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Venmo data\n",
    "venmo_df =spark.read.parquet('VenmoSample.snappy.parquet')\n",
    "venmo_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q0: Find 10 words that are not already in thedictionary and add them to it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added words:   \n",
    "       Food: cigarette. barbeque. pepper. \n",
    "       Event: repair. Cupping. Winter. \n",
    "       Utility: laptop. dogecoin \n",
    "       Illegal/Sarcasm: toxic. motherfucker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1: Use the text dictionary and the emoji dictionary to classify Venmo‚Äôs transactions in sample dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+--------+--------------+------+-------+----+---------------+\n",
      "|Event|Travel|Food|Activity|Transportation|People|Utility|Cash|Illegal/Sarcasm|\n",
      "+-----+------+----+--------+--------------+------+-------+----+---------------+\n",
      "| üá¶üá∫|    üèî|  üçá|      üëæ|            üöÑ|    üòÄ|      ‚ö°|null|           null|\n",
      "| üá´üá∑|     ‚õ∞|  üçà|      üï¥|            üöÖ|    üòÉ|     üí°|null|           null|\n",
      "|   üéÇ|    üåã|  üçâ|      üé™|            üöÜ|    üòÑ|     üîå|null|           null|\n",
      "|   üõç|    üóª|  üçä|      üé≠|            üöá|    üòÅ|     üì∫|null|           null|\n",
      "| üá®üá¶|    üèï|  üçã|      üé®|            üöà|    üòÜ|     üîå|null|           null|\n",
      "+-----+------+----+--------+--------------+------+-------+----+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+---------+---------+--------+------+--------------+-----------+-----+---------------+\n",
      "|    People|     Food|    Event|Activity|Travel|Transportation|    Utility| Cash|Illegal/Sarcasm|\n",
      "+----------+---------+---------+--------+------+--------------+-----------+-----+---------------+\n",
      "|    friend|     food| birthday|    ball| beach|          lyft|       bill| atm |      addiction|\n",
      "|friendship|      bbq|christmas|    boat| place|          uber|      cable|bank |           drug|\n",
      "|      baby|     bean|    happy|     bar|    la|           cab|        fee|cash |          wangs|\n",
      "|       boy|    latte|     bday|    book| world|           bus|   electric|money|           weed|\n",
      "|      girl|breakfast|  wedding|    club| hotel|           car|electricity| buck|           anal|\n",
      "+----------+---------+---------+--------+------+--------------+-----------+-----+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+---------+---------+--------+------+--------------+-----------+-----+---------------+\n",
      "|    People|     Food|    Event|Activity|Travel|Transportation|    Utility| Cash|Illegal/Sarcasm|\n",
      "+----------+---------+---------+--------+------+--------------+-----------+-----+---------------+\n",
      "|    friend|     food| birthday|    ball| beach|          lyft|       bill| atm |      addiction|\n",
      "|friendship|      bbq|christmas|    boat| place|          uber|      cable|bank |           drug|\n",
      "|      baby|     bean|    happy|     bar|    la|           cab|        fee|cash |          wangs|\n",
      "|       boy|    latte|     bday|    book| world|           bus|   electric|money|           weed|\n",
      "|      girl|breakfast|  wedding|    club| hotel|           car|electricity| buck|           anal|\n",
      "+----------+---------+---------+--------+------+--------------+-----------+-----+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the text and emoji dictionary with added new words\n",
    "emoji = spark.read.option(\"header\", True) \\\n",
    "    .csv(\"Venmo_Emoji_Classification_Dictionary.csv\") \\\n",
    "    .withColumn(\"Cash\", lit(None)) \\\n",
    "    .withColumn(\"Illegal/Sarcasm\", lit(None))\n",
    "emoji.show(5)\n",
    "word = spark.read.option(\"header\", True) \\\n",
    "    .csv('Venmo Word Classification Dictonary BAX-423 - Word_Dict.csv', header=True)\n",
    "word.show(5)\n",
    "\n",
    "# Merge the two dataset\n",
    "dic = word.unionByName(emoji)\n",
    "dic.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------------+-------------------+------------+-----------+--------------------+---------------+\n",
      "|  user1|  user2|transaction_type|           datetime| description|is_business|            story_id|word_collection|\n",
      "+-------+-------+----------------+-------------------+------------+-----------+--------------------+---------------+\n",
      "|1218774|1528945|         payment|2015-11-27 10:48:19|        Uber|      false|5657c473cd03c9af2...|         [uber]|\n",
      "|5109483|4782303|         payment|2015-06-17 11:37:04|      Costco|      false|5580f9702b64f70ab...|       [costco]|\n",
      "|4322148|3392963|         payment|2015-06-19 07:05:31|Sweaty balls|      false|55835ccb1a624b14a...|[sweaty, balls]|\n",
      "| 469894|1333620|          charge|2016-06-03 23:34:13|          üé•|      false|5751b185cd03c9af2...|           [üé•]|\n",
      "|2960727|3442373|         payment|2016-05-29 23:23:42|           ‚ö°|      false|574b178ecd03c9af2...|            [‚ö°]|\n",
      "+-------+-------+----------------+-------------------+------------+-----------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenize description\n",
    "df_tokenized = Tokenizer(inputCol=\"description\", outputCol=\"word_collection\").transform(venmo_df)\n",
    "df_tokenized.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each category, create lists for dictionary\n",
    "people=[i[0] for i in dic.select(dic.columns[0]).collect()]\n",
    "food=[i[0] for i in dic.select(dic.columns[1]).collect()]\n",
    "event=[i[0] for i in dic.select(dic.columns[2]).collect()]\n",
    "activity=[i[0] for i in dic.select(dic.columns[3]).collect()]\n",
    "travel=[i[0] for i in dic.select(dic.columns[4]).collect()]\n",
    "transportation=[i[0] for i in dic.select(dic.columns[5]).collect()]\n",
    "utility=[i[0] for i in dic.select(dic.columns[6]).collect()]\n",
    "cash=[i[0] for i in dic.select(dic.columns[7]).collect()]\n",
    "illegal=[i[0] for i in dic.select(dic.columns[8]).collect()]\n",
    "# Define a function to classify the words\n",
    "def word_category(x):\n",
    "    word_cate = []\n",
    "    for var in x:\n",
    "        if var in people:\n",
    "            word_cate.append('People')\n",
    "        if var in food:\n",
    "            word_cate.append('Food')\n",
    "        if var in event:\n",
    "            word_cate.append('Event')\n",
    "        if var in activity:\n",
    "            word_cate.append('Activity')\n",
    "        if var in travel:\n",
    "            word_cate.append('Travel')\n",
    "        if var in transportation:\n",
    "            word_cate.append('Transportation')\n",
    "        if var in utility:\n",
    "            word_cate.append('Utility')\n",
    "        if var in cash:\n",
    "            word_cate.append('Cash')\n",
    "        if var in illegal:\n",
    "            word_cate.append('Illegal-Sarcasm')\n",
    "    \n",
    "    if len(word_cate)==0:\n",
    "            word_cate.append('Other')\n",
    "    return word_cate\n",
    "# Define a function to classify each transaction's category\n",
    "word_categorizer=function.udf(lambda x: word_category(x), ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------------+-------------------+--------------------+-----------+--------------------+--------------------+--------------------+\n",
      "|   user1|  user2|transaction_type|           datetime|         description|is_business|            story_id|     word_collection|            category|\n",
      "+--------+-------+----------------+-------------------+--------------------+-----------+--------------------+--------------------+--------------------+\n",
      "| 1218774|1528945|         payment|2015-11-27 10:48:19|                Uber|      false|5657c473cd03c9af2...|              [uber]|    [Transportation]|\n",
      "| 5109483|4782303|         payment|2015-06-17 11:37:04|              Costco|      false|5580f9702b64f70ab...|            [costco]|              [Food]|\n",
      "| 4322148|3392963|         payment|2015-06-19 07:05:31|        Sweaty balls|      false|55835ccb1a624b14a...|     [sweaty, balls]|   [Illegal-Sarcasm]|\n",
      "|  469894|1333620|          charge|2016-06-03 23:34:13|                  üé•|      false|5751b185cd03c9af2...|                [üé•]|             [Event]|\n",
      "| 2960727|3442373|         payment|2016-05-29 23:23:42|                   ‚ö°|      false|574b178ecd03c9af2...|                 [‚ö°]|           [Utility]|\n",
      "| 3977544|2709470|         payment|2016-09-29 22:12:07|          Chipotlaid|      false|57ed2f4723e064eac...|        [chipotlaid]|             [Other]|\n",
      "| 3766386|4209061|         payment|2016-05-20 10:31:15|     kitchen counter|      false|573e8503cd03c9af2...|  [kitchen, counter]|     [Food, Utility]|\n",
      "|  730075| 804466|         payment|2016-05-26 04:46:45|                Food|      false|57461d46cd03c9af2...|              [food]|              [Food]|\n",
      "| 5221751|4993533|         payment|2016-07-14 22:53:49|               Zaxby|      false|5787b58d23e064eac...|             [zaxby]|             [Other]|\n",
      "| 6843582|7308338|         payment|2016-08-31 10:32:46|           Fan sucks|      false|57c64fdf23e064eac...|        [fan, sucks]|             [Other]|\n",
      "| 5317324|3942984|         payment|2016-01-04 09:11:25|                  üë†|      false|5689c6bdcd03c9af2...|                [üë†]|             [Other]|\n",
      "| 1134661|1556430|         payment|2015-10-09 01:53:52|         Thanks babe|      false|5616bbc0cd03c9af2...|      [thanks, babe]|    [People, People]|\n",
      "| 4238868|4879587|         payment|2015-10-04 08:28:01|                  üç∫|      false|561080a1cd03c9af2...|                [üç∫]|              [Food]|\n",
      "|11719500|8702716|         payment|2016-07-07 21:40:39|                   ‚õΩ|      false|577e69e723e064eac...|                 [‚õΩ]|    [Transportation]|\n",
      "| 3625798|5692302|         payment|2016-10-16 14:43:41|Hey man  it's bee...|      false|58032fad23e064eac...|[hey, man, , it's...|[People, Cash, Il...|\n",
      "|  613908|3045405|          charge|2016-05-07 06:42:17|         Getaway car|      false|572d2bd9cd03c9af2...|      [getaway, car]|    [Transportation]|\n",
      "| 4682257|1870271|         payment|2016-02-24 09:14:12|     üîÆ gypsy things|      false|56cd03e4cd03c9af2...| [üîÆ, gypsy, things]|             [Other]|\n",
      "| 9414481|2869012|         payment|2016-04-09 09:19:46|                  üî¥|      false|570866c2cd03c9af2...|                [üî¥]|             [Other]|\n",
      "|  241386|2580543|         payment|2015-05-17 06:00:19|           Furniture|      false|5557cc0407f81c33e...|         [furniture]|           [Utility]|\n",
      "|  656477| 656214|          charge|2013-12-14 22:43:27|bed bath mostly b...|      false|52ac6e93d56b6bac5...|[bed, bath, mostl...|           [Utility]|\n",
      "+--------+-------+----------------+-------------------+--------------------+-----------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tokenized = df_tokenized.withColumn('category',word_categorizer(function.col('word_collection')))\n",
    "df_tokenized.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2: What is the percent of emoji only transactions? Which are the top 5 most popular emoji? Which are the top three most popular emoji categories?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Percent of emoji only transactions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a funciton for creating a emoji identifier column\n",
    "import emoji\n",
    "def is_emoji(x):\n",
    "    result = []\n",
    "    for val in x:\n",
    "        if val in emoji.UNICODE_EMOJI_ENGLISH:\n",
    "            result.append(val)\n",
    "    return result\n",
    "\n",
    "def not_emoji(x):\n",
    "    result2 = []\n",
    "    for val in x:\n",
    "        if val not in emoji.UNICODE_EMOJI_ENGLISH:\n",
    "            result2.append(val)\n",
    "    return result2\n",
    "\n",
    "emoji_filter = function.udf(lambda x: is_emoji(x), ArrayType(StringType()))\n",
    "word_filter = function.udf(lambda x: not_emoji(x), ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "description=df_tokenized.select('user1','user2','datetime', emoji_filter('word_collection').alias('emojis'),word_filter('word_collection').alias('words'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------------+------+---------------+\n",
      "|  user1|  user2|           datetime|emojis|          words|\n",
      "+-------+-------+-------------------+------+---------------+\n",
      "|1218774|1528945|2015-11-27 10:48:19|    []|         [uber]|\n",
      "|5109483|4782303|2015-06-17 11:37:04|    []|       [costco]|\n",
      "|4322148|3392963|2015-06-19 07:05:31|    []|[sweaty, balls]|\n",
      "| 469894|1333620|2016-06-03 23:34:13|  [üé•]|             []|\n",
      "|2960727|3442373|2016-05-29 23:23:42|   [‚ö°]|             []|\n",
      "+-------+-------+-------------------+------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "description.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the word list is empty. If it's empty return 1 indicating there are only emojis\n",
    "check = lambda x: 0 if len(x) > 0 else 1\n",
    "emoji_only_checker = function.udf(lambda words:check(words),IntegerType())\n",
    "emoji_only = description.select('user1','user2','datetime','emojis','words', emoji_only_checker('words').alias('is_emoji_only'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_only_num = emoji_only.where('is_emoji_only=1').count()\n",
    "total = emoji_only.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of emoji only transactions:  14.445342469855424 %\n"
     ]
    }
   ],
   "source": [
    "print('Percent of emoji only transactions: ', emoji_only_num/total*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 5 emojis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|emojis|count(emojis)|\n",
      "+------+-------------+\n",
      "|  [üçï]|        55226|\n",
      "|  [üçª]|        43113|\n",
      "|  [üç¥]|        34173|\n",
      "|  [üç∫]|        28163|\n",
      "|   [‚õΩ]|        23596|\n",
      "+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emoji_count = description.select('emojis')\n",
    "emoji_count.createOrReplaceTempView('emojis_count')\n",
    "# Find the top 5 popolar emojis\n",
    "spark.sql('''select emojis, count(emojis) from emojis_count \n",
    "              where emojis is not null and cardinality(emojis) <> 0\n",
    "              group by emojis \n",
    "              order by count(emojis) desc''').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 3 category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the categorize function again to find the category for emojis\n",
    "emoji_cate=emoji_count.withColumn('category', word_categorizer(function.col('emojis')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|  category|count(category)|\n",
      "+----------+---------------+\n",
      "|    [Food]|         409599|\n",
      "|  [People]|         274526|\n",
      "|[Activity]|         108233|\n",
      "+----------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the top 3 category with emojis\n",
    "# Remove the is with empty category\n",
    "emoji_cate=emoji_cate.filter(col('category')[0] != 'Other') # function.size can be used to see the length of column\n",
    "emoji_cate.createOrReplaceTempView('emoji_category')\n",
    "spark.sql('''select category, count(category) \n",
    "               from emoji_category\n",
    "               group by category \n",
    "               order by count(category) desc''').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percent of emoji only transactions is 14.4%.\n",
    "\n",
    "The top 5 most popular emoji are: üçï üçª üç¥ üç∫ ‚õΩ\n",
    "\n",
    "The top three most popular emoji categories are: Food, People, and Activity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3: For each user, create a variable to indicate their spending behavior profile. For\n",
    "example, if a user has made 10 transactions, where 5 of them are food and the other 5 are\n",
    "activity, then the user‚Äôs spending profile will be 50% food and 50% activity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile= df_tokenized.select('user1','user2','category')\n",
    "# Remove entries with no category \n",
    "user_profile=user_profile.filter(function.size('category')>0)\n",
    "# Order by the user id and category\n",
    "user_profile.createOrReplaceTempView('users')\n",
    "user_spending_profile=spark.sql('''select * from users order by user1,category''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1_spending_profile=user_spending_profile.select('user1', function.explode('category').alias(\"category\")).groupBy('user1','category').count()\\\n",
    "                                       .select('user1','category', 'count', function.sum('count').over(Window.partitionBy(\"user1\").rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)).alias('total_count'))\\\n",
    "                                       .sort('user1', 'category')\n",
    "# Calculate the proprotion of each category\n",
    "user1_spending_profile=user1_spending_profile.select('user1','category', bround(100*col(\"count\")/col(\"total_count\")).alias(\"percentage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----+-----+----+---------------+-----+------+--------------+------+-------+\n",
      "|user1|Activity|Cash|Event|Food|Illegal-Sarcasm|Other|People|Transportation|Travel|Utility|\n",
      "+-----+--------+----+-----+----+---------------+-----+------+--------------+------+-------+\n",
      "|    2|    null|null| null|null|           null|100.0|  null|          null|  null|   null|\n",
      "|    3|    null|null| null|17.0|           null| 50.0|  17.0|          null|  null|   17.0|\n",
      "|    4|    25.0|null| null|25.0|           12.0| 25.0|  null|          null|  12.0|   null|\n",
      "|   10|     7.0|null| null|43.0|           null| 29.0|  14.0|           7.0|  null|   null|\n",
      "|   11|     7.0|null| 11.0|11.0|           null| 52.0|  11.0|          null|   4.0|    4.0|\n",
      "|   12|    20.0|null| 10.0|10.0|           null| 40.0|  null|          null|  null|   20.0|\n",
      "|   13|    12.0|null|  9.0|18.0|            3.0| 15.0|  24.0|           9.0|   3.0|    9.0|\n",
      "|   16|    10.0|null| null|60.0|           null| 20.0|  null|          null|  10.0|   null|\n",
      "|   19|    20.0|null| 20.0|20.0|           null| 20.0|  null|          null|  20.0|   null|\n",
      "|   28|    null|null| null|null|           null|100.0|  null|          null|  null|   null|\n",
      "|   34|    null|null| null|50.0|           null| 25.0|  null|          null|  25.0|   null|\n",
      "|   42|     7.0| 7.0| 33.0|13.0|            7.0| 13.0|  20.0|          null|  null|   null|\n",
      "|   43|    14.0|null| null|22.0|            4.0| 47.0|   6.0|           4.0|   2.0|   null|\n",
      "|   47|    null|25.0| 25.0|12.0|           12.0| null|  12.0|          null|  null|   12.0|\n",
      "|   52|    null|null| null|50.0|           null| 50.0|  null|          null|  null|   null|\n",
      "|   56|    50.0|null| null|null|           null| 50.0|  null|          null|  null|   null|\n",
      "|  112|    null|null| null|null|           null|100.0|  null|          null|  null|   null|\n",
      "|  126|    50.0|null| null|null|           null| 50.0|  null|          null|  null|   null|\n",
      "|  129|   100.0|null| null|null|           null| null|  null|          null|  null|   null|\n",
      "|  134|    null|null| null|null|           null|100.0|  null|          null|  null|   null|\n",
      "+-----+--------+----+-----+----+---------------+-----+------+--------------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pivot the table\n",
    "user1_spending_profile=user1_spending_profile.groupBy(\"user1\").pivot(\"category\").sum(\"percentage\").sort(\"user1\")\n",
    "user1_spending_profile.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4: In the previous question, you got a static spending profile. However, life and social\n",
    "networks are evolving over time. Therefore, let‚Äôs explore how a user‚Äôs spending profile is\n",
    "evolving over her lifetime in Venmo. First of all, you need to analyze a user‚Äôs transactions in\n",
    "monthly intervals, starting from 0 (indicating their first transaction only ) up to 12.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spending_profile = df_tokenized.select('user1','user2','datetime', 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------------+-----------------+\n",
      "|  user1|  user2|           datetime|         category|\n",
      "+-------+-------+-------------------+-----------------+\n",
      "|1218774|1528945|2015-11-27 10:48:19| [Transportation]|\n",
      "|5109483|4782303|2015-06-17 11:37:04|           [Food]|\n",
      "|4322148|3392963|2015-06-19 07:05:31|[Illegal-Sarcasm]|\n",
      "| 469894|1333620|2016-06-03 23:34:13|          [Event]|\n",
      "|2960727|3442373|2016-05-29 23:23:42|        [Utility]|\n",
      "+-------+-------+-------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spending_profile.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dynamic profile\n",
    "# extract month from date time\n",
    "spending_profile.createOrReplaceTempView('spending_profile')\n",
    "user_profile_dynamic=spark.sql('''select user1,\n",
    "                                  CAST(MONTHS_BETWEEN(datetime, FIRST_VALUE(datetime) OVER (PARTITION BY user1 ORDER BY datetime)) as INT) as month,\n",
    "                                  category\n",
    "                                  from spending_profile''')\n",
    "# filter for up to 12 month\n",
    "user_profile_dynamic=user_profile_dynamic.filter(col('month') <= 12).sort('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------+\n",
      "|user1|month|    category|\n",
      "+-----+-----+------------+\n",
      "|  830|    0|   [Utility]|\n",
      "|43443|    0|     [Other]|\n",
      "|44379|    0|     [Other]|\n",
      "|44964|    0|     [Other]|\n",
      "|45016|    0|[Food, Food]|\n",
      "+-----+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_profile_dynamic.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstack the category and calcualte the percentage \n",
    "user_profile_dynamic=user_profile_dynamic.select('user1','month', function.explode('category').alias(\"category\")).groupBy('user1','month','category')\\\n",
    "                                  .count().select('user1','month','category','count', function.sum('count').over(Window.partitionBy(\"user1\",'month')).alias('total_count'))\\\n",
    "                                  .sort('user1', 'month','category')\n",
    "# calculate the percentage\n",
    "user_profile_dynamic=user_profile_dynamic.select(\"user1\",\"month\",'category','count','total_count', bround(100*col(\"count\")/col(\"total_count\")).alias(\"percentage\"))\n",
    "user_profile_dynamic=user_profile_dynamic.select(\"user1\",\"month\",'category',\"percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table\n",
    "summary_user_profile = user_profile_dynamic.groupBy('user1','month').pivot(\"category\").sum(\"percentage\").sort(\"user1\",'month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repalce null with 0\n",
    "summary_user_profile.createOrReplaceTempView(\"summary_profile\")\n",
    "summary_user_profile = spark.sql('''\n",
    "select user1, month,\n",
    "       coalesce(`Activity`, 0) AS Activity,\n",
    "       coalesce(`Cash`, 0) AS Cash,\n",
    "       coalesce(`Event`, 0) AS Event,\n",
    "       coalesce(`Food`, 0) AS Food,\n",
    "       coalesce(`Illegal-Sarcasm`, 0) AS `Illegal-Sarcasm`,\n",
    "       coalesce(`Other`, 0) AS Other,\n",
    "       coalesce(`People`, 0) AS People,\n",
    "       coalesce(`Transportation`, 0) AS Transportation,\n",
    "       coalesce(`Travel`, 0) AS Travel,\n",
    "       coalesce(`Utility`, 0) AS Utility\n",
    "from summary_profile \n",
    "order by user1, month\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------+----+-----+-----+---------------+-----+------+--------------+------+-------+\n",
      "|user1|month|Activity|Cash|Event| Food|Illegal-Sarcasm|Other|People|Transportation|Travel|Utility|\n",
      "+-----+-----+--------+----+-----+-----+---------------+-----+------+--------------+------+-------+\n",
      "|    2|    0|     0.0| 0.0|  0.0|  0.0|            0.0|100.0|   0.0|           0.0|   0.0|    0.0|\n",
      "|    3|    0|     0.0| 0.0|  0.0| 17.0|            0.0| 50.0|  17.0|           0.0|   0.0|   17.0|\n",
      "|    4|    0|     0.0| 0.0|  0.0| 67.0|           33.0|  0.0|   0.0|           0.0|   0.0|    0.0|\n",
      "|   10|    0|     0.0| 0.0|  0.0| 50.0|            0.0|  0.0|  50.0|           0.0|   0.0|    0.0|\n",
      "|   10|    1|    50.0| 0.0|  0.0|  0.0|            0.0| 50.0|   0.0|           0.0|   0.0|    0.0|\n",
      "|   10|    3|     0.0| 0.0|  0.0| 50.0|            0.0|  0.0|  50.0|           0.0|   0.0|    0.0|\n",
      "|   10|    4|     0.0| 0.0|  0.0|  0.0|            0.0|100.0|   0.0|           0.0|   0.0|    0.0|\n",
      "|   11|    0|     0.0| 0.0|  0.0|100.0|            0.0|  0.0|   0.0|           0.0|   0.0|    0.0|\n",
      "|   11|    2|     0.0| 0.0|  0.0|  0.0|            0.0|100.0|   0.0|           0.0|   0.0|    0.0|\n",
      "|   11|    3|     0.0| 0.0|100.0|  0.0|            0.0|  0.0|   0.0|           0.0|   0.0|    0.0|\n",
      "|   11|    4|    33.0| 0.0|  0.0|  0.0|            0.0| 33.0|   0.0|           0.0|   0.0|   33.0|\n",
      "|   11|    5|     0.0| 0.0|  0.0|  0.0|            0.0|  0.0| 100.0|           0.0|   0.0|    0.0|\n",
      "|   12|    0|    50.0| 0.0|  0.0|  0.0|            0.0|  0.0|   0.0|           0.0|   0.0|   50.0|\n",
      "|   12|    4|     0.0| 0.0|  0.0|  0.0|            0.0|100.0|   0.0|           0.0|   0.0|    0.0|\n",
      "|   12|    7|     0.0| 0.0|100.0|  0.0|            0.0|  0.0|   0.0|           0.0|   0.0|    0.0|\n",
      "|   12|    9|     0.0| 0.0|  0.0|  0.0|            0.0|100.0|   0.0|           0.0|   0.0|    0.0|\n",
      "|   13|    0|     0.0| 0.0| 50.0|  0.0|            0.0|  0.0|   0.0|           0.0|  50.0|    0.0|\n",
      "|   13|    4|     0.0| 0.0|  0.0|  0.0|            0.0|  0.0| 100.0|           0.0|   0.0|    0.0|\n",
      "|   13|    5|     0.0| 0.0|  0.0|100.0|            0.0|  0.0|   0.0|           0.0|   0.0|    0.0|\n",
      "|   13|    8|     0.0| 0.0|  0.0|  0.0|            0.0|100.0|   0.0|           0.0|   0.0|    0.0|\n",
      "+-----+-----+--------+----+-----+-----+---------------+-----+------+--------------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_user_profile.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5: Write a script to find a user‚Äôs friends and friends of friends (Friend definition:Auser‚Äôs friend is someone who has transacted with theuser, either sending money to the user orreceiving money from the user).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the direct firends of each user\n",
    "def first_degree_friends(user_id):\n",
    "    user1=venmo_df.select(\"user1\",\"user2\").where(\"user1=={}\".format(user_id))\n",
    "    user2=venmo_df.select(\"user2\",\"user1\").where(\"user2=={}\".format(user_id))\n",
    "    friends=user1.union(user2).distinct().sort(\"user2\").select(\"user2\")\n",
    "    return friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| user2|\n",
      "+------+\n",
      "|    43|\n",
      "|   220|\n",
      "|191142|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display direct friends of user_id, for example, user_id = 3.\n",
    "first_degree_friends(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return second degree friends\n",
    "def find_friends_of_friends():\n",
    "    friends_new=spark.sql(\"WITH t AS \\\n",
    "    (SELECT DISTINCT user1,user2 FROM ((SELECT user1, user2 FROM parquet) UNION (SELECT user2,user1 FROM parquet) ))\\\n",
    "    SELECT DISTINCT t1.user1 AS user1,t2.user2 AS 2nd_degree_friends\\\n",
    "    FROM t t1 LEFT JOIN t t2 on t1.user2=t2.user1 AND t1.user1 !=t2.user2\\\n",
    "    WHERE t2.user2 IS NOT NULL and t2.user2 NOT IN (SELECT t3.user2 FROM t t3 WHERE t3.user1=t1.user1)\\\n",
    "    ORDER BY user1,2nd_degree_friends\")\n",
    "    return friends_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|user1|2nd_degree_friends|\n",
      "+-----+------------------+\n",
      "|    2|                 3|\n",
      "|    2|                10|\n",
      "|    2|                19|\n",
      "|    2|                96|\n",
      "|    2|               629|\n",
      "|    2|              3565|\n",
      "|    2|             20530|\n",
      "|    2|             20639|\n",
      "|    2|             47104|\n",
      "|    2|             49778|\n",
      "|    2|             55895|\n",
      "|    2|             72106|\n",
      "|    2|             82697|\n",
      "|    2|            183628|\n",
      "|    2|            276439|\n",
      "|    2|            297967|\n",
      "|    2|            307603|\n",
      "|    2|            316862|\n",
      "|    2|            613769|\n",
      "|    2|            851628|\n",
      "+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_friends_of_friends().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6: Calculate social network metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YDgBIV_E8Tq"
   },
   "source": [
    "q6i - Number of friends and number of friends of friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "zjWf74rlGHn8"
   },
   "outputs": [],
   "source": [
    "# Calculate the number of days passed wince the user's first transaction\n",
    "assign_month = function.udf(lambda x: 0 if (x == 0) else math.ceil(x/30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HoYRfYuTKAhU",
    "outputId": "bf2a792d-a4b4-4fa8-9ed2-d20dff726f3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------------+\n",
      "|  user1|  user2|           datetime|\n",
      "+-------+-------+-------------------+\n",
      "|1218774|1528945|2015-11-27 10:48:19|\n",
      "|5109483|4782303|2015-06-17 11:37:04|\n",
      "|4322148|3392963|2015-06-19 07:05:31|\n",
      "| 469894|1333620|2016-06-03 23:34:13|\n",
      "|2960727|3442373|2016-05-29 23:23:42|\n",
      "+-------+-------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Merge\n",
    "friend_to = venmo_df.select('user1', 'user2', 'datetime')\n",
    "friend_from = venmo_df.select('user2', 'user1', 'datetime')\n",
    "friend_all = friend_to.union(friend_from)\n",
    "friend_all.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "AzKGD9r7IN7K"
   },
   "outputs": [],
   "source": [
    "# assign a 'month' to user1 and user2\n",
    "\n",
    "w1 = Window.partitionBy('user1')\n",
    "friend_all_days = friend_all.withColumn(\"days\", function.datediff(\"datetime\", function.min(\"datetime\").over(w1)))\n",
    "group_user1 = friend_all_days.withColumn('month', assign_month(function.col('days')))\n",
    "group_user1 = group_user1.withColumn(\"month\", group_user1[\"month\"].cast(IntegerType()))\n",
    "\n",
    "w2 = Window.partitionBy('user2')\n",
    "group_user2 = group_user1.withColumn(\"days2\", function.datediff(\"datetime\", function.min(\"datetime\").over(w2)))\n",
    "group_month = group_user2.withColumn('month2', assign_month(function.col('days2')))\n",
    "group_month = group_month.withColumn(\"month2\", group_month[\"month2\"].cast(IntegerType()))\n",
    "\n",
    "group_month.createOrReplaceTempView(\"group_month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "fQ3wPdnSISJn"
   },
   "outputs": [],
   "source": [
    "total_friend = spark.sql(\"\"\"SELECT user1, month, COUNT(DISTINCT user2) AS FRIEND_NUM\n",
    "                        FROM group_month t1 \n",
    "                        WHERE month <= 12\n",
    "                        GROUP BY user1, month\n",
    "                        ORDER BY user1, month\"\"\")\n",
    "total_friend.createOrReplaceTempView(\"total_friend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "jARMNHy6K8_W"
   },
   "outputs": [],
   "source": [
    "# attach number of friends' of user2 to the table\n",
    "\n",
    "num_friends_user2 = spark.sql(\"\"\"SELECT t1.*, t2.friend_num\n",
    "                        FROM group_month t1\n",
    "                            INNER JOIN total_friend t2 \n",
    "                                ON t1.user2 = t2.user1\n",
    "                                AND t1.month2 = t2.month\n",
    "                        ORDER BY user1, user2\"\"\")\n",
    "num_friends_user2.createOrReplaceTempView(\"num_friends_user2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "1_LEAxwtLBFL"
   },
   "outputs": [],
   "source": [
    "# Select only distinct user2 (user1's friends) and less than 12 months\n",
    "\n",
    "num_fof_month = spark.sql(\"\"\"SELECT DISTINCT user1, month, user2, friend_num\n",
    "                            FROM num_friends_user2\n",
    "                            WHERE month <= 12\n",
    "                            ORDER BY user1, month\"\"\")\n",
    "num_fof_month.createOrReplaceTempView(\"num_fof_month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "pdfzJmS-LImN"
   },
   "outputs": [],
   "source": [
    "# join the result\n",
    "\n",
    "num_fof_month2 = spark.sql(\"\"\"SELECT t1.user1, t1.month, IFNULL(SUM(t2.friend_num), 0) AS fof_num\n",
    "                        FROM total_friend t1\n",
    "                            LEFT JOIN num_fof_month t2\n",
    "                            ON t1.user1 = t2.user1\n",
    "                            AND t1.month = t2.month\n",
    "                        WHERE t1.month <= 12\n",
    "                        GROUP BY t1.user1, t1.month\n",
    "                        ORDER BY t1.user1, t1.month\"\"\")\n",
    "num_fof_month2.createOrReplaceTempView(\"num_fof_month2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "b4eUEW4VLQ3U"
   },
   "outputs": [],
   "source": [
    "## Combine the number of direct friends and friends' friends\n",
    "num_f_fof = spark.sql(\"\"\"SELECT t1.user1, t1.month, t1.friend_num, t2.fof_num\n",
    "                        FROM total_friend t1 \n",
    "                            LEFT JOIN num_fof_month2 t2\n",
    "                            ON t1.user1 = t2.user1\n",
    "                            AND t1.month = t2.month\n",
    "                        WHERE t1.month <= 12\n",
    "                        ORDER BY t1.user1, t1.month\"\"\")\n",
    "num_f_fof.createOrReplaceTempView(\"num_f_fof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcNxKZQmLX3q",
    "outputId": "73dd8245-7522-4192-c854-5638a1b0af0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----------+-------+\n",
      "|user1|month|friend_num|fof_num|\n",
      "+-----+-----+----------+-------+\n",
      "|    2|    0|         1|      1|\n",
      "|    3|    0|         1|      0|\n",
      "|    3|    1|         1|      0|\n",
      "|    3|    3|         1|      0|\n",
      "|    3|    4|         4|      3|\n",
      "|    3|    5|         1|      0|\n",
      "|    4|    0|         1|      1|\n",
      "|    4|    1|         1|      1|\n",
      "|    4|    2|         1|      1|\n",
      "|    6|    0|         1|      1|\n",
      "|    6|   10|         1|      1|\n",
      "|    8|    0|         1|      1|\n",
      "|    8|    2|         1|      2|\n",
      "|    8|    7|         2|      2|\n",
      "|    8|    9|         1|      1|\n",
      "|    8|   10|         1|      2|\n",
      "|    9|    0|         1|      1|\n",
      "|    9|    2|         1|      1|\n",
      "|    9|    5|         1|      1|\n",
      "|    9|    7|         1|      1|\n",
      "+-----+-----+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of friends and number of friends of friends table\n",
    "num_f_fof.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfpse8-pTxoz"
   },
   "source": [
    "q6ii - Clustering coefficient of a user's network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "kYxfywbOTxEf"
   },
   "outputs": [],
   "source": [
    "# Calculate possible triplets\n",
    "\n",
    "triplet_pos = spark.sql(\"\"\"\n",
    "                        SELECT user1, month, \n",
    "                            CASE \n",
    "                                WHEN friend_num <= 1 THEN 0 \n",
    "                                ELSE INT(friend_num * (friend_num -1)/2)\n",
    "                                END AS tri_pos \n",
    "                        FROM total_friend \n",
    "                        WHERE month <= 12\n",
    "                        ORDER BY 1,2\"\"\")\n",
    "triplet_pos.createOrReplaceTempView(\"triplet_pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "7R-MBMs3UnhF"
   },
   "outputs": [],
   "source": [
    "# Calculate existed triplets\n",
    "\n",
    "tri_actual = spark.sql(\"\"\"\n",
    "                        SELECT t1.user1, t1.month, IFNULL(COUNT(DISTINCT *), 0) AS tri_act\n",
    "                        FROM group_month t1\n",
    "                            INNER JOIN group_month t2\n",
    "                                ON t1.month <= 12\n",
    "                                AND t1.user2 = t2.user1\n",
    "                            LEFT JOIN (SELECT DISTINCT t3.user1, t3.month, t3.user2\n",
    "                                        FROM group_month t3\n",
    "                                        WHERE t3.month <= 12\n",
    "                                        ) t3\n",
    "                                ON t3.user2 = t2.user2\n",
    "                                AND t3.user1 = t1.user1\n",
    "                                AND t3.month = t1.month\n",
    "                        GROUP BY t1.user1, t1.month\n",
    "                        ORDER BY t1.user1, t1.month\"\"\")\n",
    "tri_actual.createOrReplaceTempView(\"tri_actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "jCgzk5pSUpd7"
   },
   "outputs": [],
   "source": [
    "# Calculate clustering coefficients\n",
    "\n",
    "cluster = spark.sql(\"\"\"\n",
    "                        SELECT t1.user1, t1.month, IFNULL(tri_act/tri_pos, 0) AS cluster_coef\n",
    "                        FROM triplet_pos t2\n",
    "                        LEFT JOIN tri_actual t1\n",
    "                        ON t1.user1 = t2.user1\n",
    "                        AND t1.month = t2.month\n",
    "                        ORDER BY t1.user1, t1.month\"\"\")\n",
    "cluster.createOrReplaceTempView(\"cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UOdhhjqpUrOR",
    "outputId": "ba7eed8e-c483-44a5-b3cb-7e86169d9980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------+\n",
      "|user1|month|cluster_coef|\n",
      "+-----+-----+------------+\n",
      "|    2|    0|         0.0|\n",
      "|    3|    0|         0.0|\n",
      "|    3|    1|         0.0|\n",
      "|    3|    3|         0.0|\n",
      "|    3|    4|         0.0|\n",
      "|    3|    5|         0.0|\n",
      "|    4|    0|         0.0|\n",
      "|    4|    1|         0.0|\n",
      "|    4|    2|         0.0|\n",
      "|    6|    0|         0.0|\n",
      "|    6|   10|         0.0|\n",
      "|    8|    0|         0.0|\n",
      "|    8|    2|         0.0|\n",
      "|    8|    7|         0.0|\n",
      "|    8|    9|         0.0|\n",
      "|    8|   10|         0.0|\n",
      "|    9|    0|         0.0|\n",
      "|    9|    2|         0.0|\n",
      "|    9|    5|         0.0|\n",
      "|    9|    7|         0.0|\n",
      "+-----+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJQGCF3kiLWP"
   },
   "source": [
    "6iii- Calculate the page rank of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "1ORLSqiN3PO6"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "#from graphframes.examples import Graphs\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "from graphframes import GraphFrame\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "d1i52UY93Rpw"
   },
   "outputs": [],
   "source": [
    "#create vertices table\n",
    "user1=venmo_df.select(\"user1\")\n",
    "user2=venmo_df.select(\"user2\")\n",
    "user_id=user1.union(user2).distinct()\n",
    "vertices=user_id.withColumnRenamed('user1',\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "1muPYdvQ3Z42"
   },
   "outputs": [],
   "source": [
    "#create edges table\n",
    "edges=venmo_df.select(\"user1\",\"user2\",\"transaction_type\").withColumnRenamed('user1','src').withColumnRenamed('user2','dst')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "id": "CQLgDTXk3ehC",
    "outputId": "b6d025e5-4205-4553-fbc4-c504ccd114b3"
   },
   "outputs": [],
   "source": [
    "#GraphFrame -- Error -- Output ommitted beacuaes graphframe was not working with spark\n",
    "g = GraphFrame(vertices, edges)\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "PqtDlpCS3lV3",
    "outputId": "1258bdad-7856-4912-b4df-fe392c5d9e37"
   },
   "outputs": [],
   "source": [
    "#Display graphframe results -- Unable to display \n",
    "results = g.pageRank(resetProbability=0.15, maxIter=1)\n",
    "display(results.vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analytics with MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7: First, create your dependent variableY,i.e. the total number of transactions at lifetimepoint 12. In other words, for every user, you needto count how many transactions s/he hadcommitted during her/his twelve months in Venmo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1 = venmo_df.select(\"user1\", \"datetime\").withColumnRenamed('user1', 'users')\n",
    "user2 = venmo_df.select(\"user2\", \"datetime\").withColumnRenamed('user2', 'users')\n",
    "user_all = user1.union(user2).orderBy(\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_all = user_all.withColumn('timestamp', function.unix_timestamp('datetime', 'yyyy-MM-dd'))\n",
    "num_12 = user_all.withColumn('num_12_month', function.count('users').over(Window.partitionBy('users').orderBy('timestamp').rangeBetween(0, 365*86400))).orderBy('users', 'datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|users|num_12_month|\n",
      "+-----+------------+\n",
      "|    2|           1|\n",
      "|    3|           9|\n",
      "|    4|           4|\n",
      "|    6|           2|\n",
      "|    8|           6|\n",
      "|    9|           5|\n",
      "|   10|          12|\n",
      "|   11|          13|\n",
      "|   12|           5|\n",
      "|   13|           5|\n",
      "|   16|           7|\n",
      "|   18|           1|\n",
      "|   19|           2|\n",
      "|   24|           2|\n",
      "|   28|           2|\n",
      "|   29|           2|\n",
      "|   31|           1|\n",
      "|   32|           1|\n",
      "|   34|           5|\n",
      "|   42|           5|\n",
      "+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y = num_12.withColumn(\"earliest\", function.min(\"datetime\").over(Window.partitionBy(\"users\"))).where(col(\"datetime\") == col(\"earliest\")).drop(\"earliest\").orderBy(\"users\")\n",
    "Y = Y.select('users', 'num_12_month')\n",
    "Y.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8: Create the recency and frequency variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q8_for_life_0():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 0) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 0 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df\n",
    "\n",
    "def q8_for_life_1():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 1) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 1 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df\n",
    "\n",
    "def q8_for_life_2():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 2) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 2 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df\n",
    "\n",
    "def q8_for_life_3():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 3) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 3 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df\n",
    "\n",
    "def q8_for_life_4():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 4) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 4 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df\n",
    "\n",
    "def q8_for_life_5():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 5) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 5 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df\n",
    "\n",
    "def q8_for_life_6():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 6) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 6 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df\n",
    "\n",
    "def q8_for_life_7():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 7) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 7 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df\n",
    "\n",
    "def q8_for_life_8():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 8) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 8 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df\n",
    "\n",
    "def q8_for_life_9():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 9) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 9 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df\n",
    "\n",
    "def q8_for_life_10():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 10) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 10 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df\n",
    "\n",
    "def q8_for_life_11():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 11) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 11 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df\n",
    "\n",
    "def q8_for_life_12():\n",
    "    df = spark.sql(\"SELECT *, add_months(min(datetime) over (partition by users), 12) AS end_date FROM user_all\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *FROM df WHERE datetime <= end_date\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, datediff(end_date, datetime) as diff FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, max(diff) over (partition by users order by datetime) + 12 as diff_first_trans FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT *, row_number() over(partition by users order by datetime) trans_num FROM df\").createOrReplaceTempView(\"df\")\n",
    "    df = spark.sql(\"SELECT users, MIN(diff) AS recency, ROUND(MAX(trans_num)/MAX(diff_first_trans),4) AS frequency FROM df GROUP BY users\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+\n",
      "|users  |recency|frequency|\n",
      "+-------+-------+---------+\n",
      "|93191  |0      |null     |\n",
      "|507462 |0      |null     |\n",
      "|507479 |0      |null     |\n",
      "|516127 |0      |null     |\n",
      "|576452 |0      |null     |\n",
      "|810928 |0      |null     |\n",
      "|899821 |0      |null     |\n",
      "|944301 |0      |null     |\n",
      "|1145935|0      |null     |\n",
      "|1225172|0      |null     |\n",
      "+-------+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|2    |30     |0.0323   |\n",
      "|3    |4      |0.0645   |\n",
      "|4    |19     |0.0938   |\n",
      "|6    |30     |0.0323   |\n",
      "|8    |31     |0.0313   |\n",
      "|9    |30     |0.0323   |\n",
      "|10   |2      |0.0645   |\n",
      "|11   |22     |0.0625   |\n",
      "|12   |30     |0.0323   |\n",
      "|13   |30     |0.0323   |\n",
      "+-----+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|2    |61     |0.0159   |\n",
      "|3    |35     |0.0317   |\n",
      "|4    |29     |0.0625   |\n",
      "|6    |61     |0.0159   |\n",
      "|8    |20     |0.0317   |\n",
      "|9    |15     |0.0317   |\n",
      "|10   |11     |0.0794   |\n",
      "|11   |52     |0.0317   |\n",
      "|12   |29     |0.0317   |\n",
      "|13   |29     |0.0317   |\n",
      "+-----+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|2    |92     |0.0105   |\n",
      "|3    |4      |0.0316   |\n",
      "|4    |57     |0.043    |\n",
      "|6    |92     |0.0105   |\n",
      "|8    |51     |0.0211   |\n",
      "|9    |46     |0.0211   |\n",
      "|10   |42     |0.0526   |\n",
      "|11   |6      |0.0316   |\n",
      "|12   |59     |0.0213   |\n",
      "|13   |59     |0.0213   |\n",
      "+-----+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|2    |120    |0.0081   |\n",
      "|3    |18     |0.0635   |\n",
      "|4    |88     |0.032    |\n",
      "|6    |122    |0.0079   |\n",
      "|8    |81     |0.0159   |\n",
      "|9    |76     |0.0159   |\n",
      "|10   |15     |0.0565   |\n",
      "|11   |22     |0.0315   |\n",
      "|12   |90     |0.0159   |\n",
      "|13   |90     |0.0159   |\n",
      "+-----+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|2    |151    |0.0064   |\n",
      "|3    |28     |0.057    |\n",
      "|4    |118    |0.0256   |\n",
      "|6    |153    |0.0063   |\n",
      "|8    |112    |0.0127   |\n",
      "|9    |18     |0.019    |\n",
      "|10   |13     |0.0577   |\n",
      "|11   |3      |0.0443   |\n",
      "|12   |121    |0.0127   |\n",
      "|13   |121    |0.0127   |\n",
      "+-----+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|2    |181    |0.0053   |\n",
      "|3    |58     |0.0476   |\n",
      "|4    |149    |0.0213   |\n",
      "|6    |183    |0.0053   |\n",
      "|8    |143    |0.0105   |\n",
      "|9    |48     |0.0159   |\n",
      "|10   |43     |0.0481   |\n",
      "|11   |34     |0.0368   |\n",
      "|12   |18     |0.016    |\n",
      "|13   |6      |0.016    |\n",
      "+-----+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|2    |212    |0.0046   |\n",
      "|3    |89     |0.0407   |\n",
      "|4    |179    |0.0183   |\n",
      "|6    |214    |0.0045   |\n",
      "|8    |9      |0.0182   |\n",
      "|9    |30     |0.0181   |\n",
      "|10   |74     |0.0411   |\n",
      "|11   |2      |0.0498   |\n",
      "|12   |49     |0.0137   |\n",
      "|13   |15     |0.0183   |\n",
      "+-----+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|2    |242    |0.004    |\n",
      "|3    |120    |0.0356   |\n",
      "|4    |210    |0.0159   |\n",
      "|6    |245    |0.004    |\n",
      "|8    |40     |0.0159   |\n",
      "|9    |9      |0.0198   |\n",
      "|10   |104    |0.036    |\n",
      "|11   |24     |0.0474   |\n",
      "|12   |79     |0.012    |\n",
      "|13   |45     |0.016    |\n",
      "+-----+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|2    |273    |0.0035   |\n",
      "|3    |148    |0.0319   |\n",
      "|4    |241    |0.0141   |\n",
      "|6    |273    |0.0035   |\n",
      "|8    |23     |0.0177   |\n",
      "|9    |37     |0.0177   |\n",
      "|10   |31     |0.0355   |\n",
      "|11   |55     |0.0421   |\n",
      "|12   |26     |0.0142   |\n",
      "|13   |76     |0.0142   |\n",
      "+-----+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|2    |304    |0.0032   |\n",
      "|3    |179    |0.0287   |\n",
      "|4    |271    |0.0127   |\n",
      "|6    |14     |0.0064   |\n",
      "|8    |25     |0.019    |\n",
      "|9    |68     |0.0159   |\n",
      "|10   |11     |0.035    |\n",
      "|11   |83     |0.0382   |\n",
      "|12   |56     |0.0128   |\n",
      "|13   |17     |0.016    |\n",
      "+-----+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|2    |334    |0.0029   |\n",
      "|3    |209    |0.0261   |\n",
      "|4    |302    |0.0116   |\n",
      "|6    |44     |0.0058   |\n",
      "|8    |55     |0.0173   |\n",
      "|9    |98     |0.0145   |\n",
      "|10   |20     |0.0348   |\n",
      "|11   |25     |0.0376   |\n",
      "|12   |87     |0.0116   |\n",
      "|13   |48     |0.0145   |\n",
      "+-----+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|2    |365    |0.0027   |\n",
      "|3    |240    |0.0239   |\n",
      "|4    |332    |0.0106   |\n",
      "|6    |75     |0.0053   |\n",
      "|8    |86     |0.0159   |\n",
      "|9    |129    |0.0133   |\n",
      "|10   |51     |0.0318   |\n",
      "|11   |55     |0.0345   |\n",
      "|12   |30     |0.0133   |\n",
      "|13   |79     |0.0133   |\n",
      "+-----+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_all_t=user_all.createOrReplaceTempView(\"user_all\")\n",
    "\n",
    "q8_for_life_0().show(10, False)\n",
    "q8_for_life_1().show(10, False)\n",
    "q8_for_life_2().show(10, False)\n",
    "q8_for_life_3().show(10, False)\n",
    "q8_for_life_4().show(10, False)\n",
    "q8_for_life_5().show(10, False)\n",
    "q8_for_life_6().show(10, False)\n",
    "q8_for_life_7().show(10, False)\n",
    "q8_for_life_8().show(10, False)\n",
    "q8_for_life_9().show(10, False)\n",
    "q8_for_life_10().show(10, False)\n",
    "q8_for_life_11().show(10, False)\n",
    "q8_for_life_12().show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+---------+\n",
      "|users|recency|frequency|\n",
      "+-----+-------+---------+\n",
      "|    2|     30|   0.0323|\n",
      "|    3|      4|   0.0645|\n",
      "|    4|     19|   0.0938|\n",
      "|    6|     30|   0.0323|\n",
      "|    8|     31|   0.0313|\n",
      "|    9|     30|   0.0323|\n",
      "|   10|      2|   0.0645|\n",
      "|   11|     22|   0.0625|\n",
      "|   12|     30|   0.0323|\n",
      "|   13|     30|   0.0323|\n",
      "|   16|     23|   0.0625|\n",
      "|   18|     29|   0.0333|\n",
      "|   19|     23|   0.0625|\n",
      "|   24|     31|   0.0313|\n",
      "|   28|     20|   0.0625|\n",
      "|   29|     30|   0.0323|\n",
      "|   31|     31|   0.0313|\n",
      "|   32|     30|   0.0323|\n",
      "|   34|     31|   0.0313|\n",
      "|   42|     31|   0.0313|\n",
      "+-----+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_all = q8_for_life_1().union(q8_for_life_2())\\\n",
    "               .union(q8_for_life_3()).union(q8_for_life_4()).union(q8_for_life_5())\\\n",
    "               .union(q8_for_life_6()).union(q8_for_life_7()).union(q8_for_life_8())\\\n",
    "               .union(q8_for_life_9()).union(q8_for_life_10()).union(q8_for_life_11())\\\n",
    "               .union(q8_for_life_12())\n",
    "rf_all.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_all_list = [q8_for_life_1(),q8_for_life_2(),q8_for_life_3(),q8_for_life_4(),q8_for_life_5(),q8_for_life_6(),\n",
    "              q8_for_life_7(),q8_for_life_8(),q8_for_life_9(),q8_for_life_10(),q8_for_life_11(),q8_for_life_12()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9:Regress recency and frequency on Y. Plot MSE for each lifetime point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = []\n",
    "for i in range(1, 12):\n",
    "    df = rf_all_list[i]\n",
    "    combined_df = Y.join(df, Y.users==df.users, \"inner\")\n",
    "    assembler = VectorAssembler(inputCols = ['recency', 'frequency'], outputCol = 'covariate')\n",
    "    out = assembler.transform(combined_df)\n",
    "    sample = out.select('covariate', 'num_12_month')\n",
    "    train, test = sample.randomSplit([0.7,0.3])\n",
    "    glm = LinearRegression(labelCol='num_12_month', featuresCol='covariate')\n",
    "    model = glm.fit(train)\n",
    "    MSE.append(model.evaluate(test).meanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(MSE)\n",
    "plt.xlabel(\"lifetime point\")\n",
    "plt.ylabel(\"MSE\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu100.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu100:m69"
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
